{"cells":[{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T06:33:25.005092Z","iopub.status.busy":"2022-07-01T06:33:25.004184Z","iopub.status.idle":"2022-07-01T06:33:25.032551Z","shell.execute_reply":"2022-07-01T06:33:25.031010Z","shell.execute_reply.started":"2022-07-01T06:33:25.004940Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import Dataset, DataLoader\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","torch.manual_seed(0)\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T06:33:25.035809Z","iopub.status.busy":"2022-07-01T06:33:25.035291Z","iopub.status.idle":"2022-07-01T06:33:25.165012Z","shell.execute_reply":"2022-07-01T06:33:25.164051Z","shell.execute_reply.started":"2022-07-01T06:33:25.035759Z"},"trusted":true},"outputs":[],"source":["data = pd.read_csv('../input/landmark1/keypoint.csv', header = None)\n","print(data.shape)\n","data[0].value_counts(normalize = True)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T06:33:25.167673Z","iopub.status.busy":"2022-07-01T06:33:25.167114Z","iopub.status.idle":"2022-07-01T06:33:25.185780Z","shell.execute_reply":"2022-07-01T06:33:25.184624Z","shell.execute_reply.started":"2022-07-01T06:33:25.167641Z"},"trusted":true},"outputs":[],"source":["\n","train_data, test_data = train_test_split(data, test_size = 0.2, random_state = 0, stratify = data[0])\n","train_data.reset_index(drop=True, inplace=True)\n","test_data.reset_index(drop=True, inplace=True)\n","train_data.shape, test_data.shape\n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T06:33:25.187734Z","iopub.status.busy":"2022-07-01T06:33:25.187379Z","iopub.status.idle":"2022-07-01T06:33:25.199714Z","shell.execute_reply":"2022-07-01T06:33:25.198863Z","shell.execute_reply.started":"2022-07-01T06:33:25.187703Z"},"trusted":true},"outputs":[],"source":["torch.tensor(train_data.values[:,0], dtype = torch.float)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T06:33:25.202603Z","iopub.status.busy":"2022-07-01T06:33:25.202259Z","iopub.status.idle":"2022-07-01T06:33:25.214606Z","shell.execute_reply":"2022-07-01T06:33:25.213763Z","shell.execute_reply.started":"2022-07-01T06:33:25.202572Z"},"trusted":true},"outputs":[],"source":["class LandmarkDataset(Dataset):\n","    def __init__(self, df):\n","        self.df = df\n","    def __len__(self):\n","        return len(self.df)\n","    def __getitem__(self, index):\n","        target = torch.tensor(self.df.values[:, 0]).type(torch.LongTensor)\n","        features = torch.tensor(self.df.values[:, 1:], dtype = torch.float)\n","        return features[index], target[index]\n","    \n","    \n","train_set = LandmarkDataset(train_data)\n","test_set = LandmarkDataset(test_data)\n","len(train_set), len(test_set)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T06:33:25.216745Z","iopub.status.busy":"2022-07-01T06:33:25.216187Z","iopub.status.idle":"2022-07-01T06:33:25.228440Z","shell.execute_reply":"2022-07-01T06:33:25.226957Z","shell.execute_reply.started":"2022-07-01T06:33:25.216712Z"},"trusted":true},"outputs":[],"source":["trainloader = DataLoader(train_set, batch_size = 32, shuffle = True)\n","testloader = DataLoader(test_set, batch_size = 32, shuffle = False)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T06:33:25.230809Z","iopub.status.busy":"2022-07-01T06:33:25.230076Z","iopub.status.idle":"2022-07-01T06:33:25.283810Z","shell.execute_reply":"2022-07-01T06:33:25.282611Z","shell.execute_reply.started":"2022-07-01T06:33:25.230764Z"},"trusted":true},"outputs":[],"source":["x, y = iter(trainloader).next()\n","x.shape, y.shape"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T06:33:25.287165Z","iopub.status.busy":"2022-07-01T06:33:25.286183Z","iopub.status.idle":"2022-07-01T06:33:25.300694Z","shell.execute_reply":"2022-07-01T06:33:25.299268Z","shell.execute_reply.started":"2022-07-01T06:33:25.287109Z"},"trusted":true},"outputs":[],"source":["n_features = 42\n","hidden_size = [32, 16]\n","n_classes = len(data[0].unique())\n","class MLP(nn.Module):\n","    def __init__(self, n_features, n_classes, hidden_size):\n","        super(MLP, self).__init__()\n","        self.fc1 = nn.Linear(n_features, hidden_size[0])\n","        self.fc2 = nn.Linear(hidden_size[0], hidden_size[1])\n","        self.output = nn.Linear(hidden_size[1], n_classes)\n","        \n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        return F.log_softmax(self.output(x), dim = 1)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2022-07-01T06:33:25.303050Z","iopub.status.busy":"2022-07-01T06:33:25.302139Z","iopub.status.idle":"2022-07-01T06:35:28.556846Z","shell.execute_reply":"2022-07-01T06:35:28.555027Z","shell.execute_reply.started":"2022-07-01T06:33:25.303004Z"},"trusted":true},"outputs":[],"source":["model = MLP(n_features, n_classes, hidden_size)\n","model.to(device)\n","learning_rate = 0.001\n","epochs = 50\n","\n","optimizer = optim.Adam(model.parameters(), lr= learning_rate)\n","criterion = nn.NLLLoss()\n","\n","train_losses = []\n","test_losses = []\n","train_accuracies = []\n","test_accuracies = []\n","benchmark_accuracy = 0.95\n","for epoch in range(epochs):\n","    print(f'Epoch {epoch + 1}/{epochs}')\n","    running_accuracy = 0\n","    running_loss = 0\n","    # training\n","    for x_train_batch, y_train_batch in trainloader:\n","        x_train_batch = x_train_batch.to(device)\n","        y_train_batch = y_train_batch.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        # forward pass\n","        scores = model(x_train_batch)\n","        train_preds = torch.argmax(scores.detach(), dim=1)\n","\n","        # loss\n","        train_loss = criterion(scores, y_train_batch)\n","        running_loss += train_loss.item()\n","\n","        # train accuracy\n","        train_acc = (y_train_batch == train_preds).sum() / len(y_train_batch)\n","        running_accuracy += train_acc.item()\n","\n","        # backward pass\n","        \n","        train_loss.backward()\n","        \n","        # update paramaters\n","        \n","        optimizer.step()\n","\n","    # mean loss (all batches losses divided by the total number of batches)\n","    train_losses.append(running_loss / len(trainloader))\n","    \n","    # mean accuracies\n","    train_accuracies.append(running_accuracy / len(trainloader))\n","    \n","    # print\n","    print(f'Train loss: {train_losses[-1] :.4f}')\n","\n","    # validation\n","    model.eval()\n","    with torch.no_grad():\n","        running_accuracy = 0\n","        running_loss = 0\n","\n","        for x_test_batch, y_test_batch in testloader:\n","            x_test_batch = x_test_batch.to(device)\n","            y_test_batch = y_test_batch.to(device)\n","            # logits\n","            test_scores = model(\n","                x_test_batch)\n","\n","            # predictions\n","            test_preds = torch.argmax(test_scores, dim=1)\n","            \n","            # accuracy\n","            test_acc = (y_test_batch == test_preds).sum() / len(y_test_batch)\n","            running_accuracy += test_acc.item()\n","\n","            # loss\n","            test_loss = criterion(test_scores, y_test_batch)\n","            running_loss += test_loss.item()\n","\n","        # mean accuracy for each epoch\n","        test_accuracies.append(running_accuracy / len(testloader))\n","\n","        # mean loss for each epoch\n","        test_losses.append(running_accuracy / len(testloader))\n","        # print\n","        print(f'Test accuracy: {test_accuracies[-1]*100 :.2f}%')\n","        print('='*100)\n","        # saving best model\n","        # is current mean score (mean per epoch) greater than or equal to the benchmark?\n","        if test_accuracies[-1] > benchmark_accuracy:\n","            # save model to cpu\n","            torch.save(model.to('cpu').state_dict(), './model.pth')\n","            model.to(device) # bring back to gpu\n","\n","            # update benckmark\n","            benchmark_accuracy = test_accuracies[-1]\n","\n","    model.train()\n","\n","\n","# Plots\n","x_epochs = list(range(epochs))\n","plt.figure(figsize=(15, 6))\n","plt.subplot(1, 2, 1)\n","plt.plot(x_epochs, train_losses, marker='o', label='train')\n","plt.plot(x_epochs, test_losses, marker='o', label='test')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(x_epochs, train_accuracies, marker='o', label='train')\n","plt.plot(x_epochs, test_accuracies, marker='o', label='test')\n","plt.axhline(benchmark_accuracy, c='grey', ls='--',\n","            label=f'Best_accuracy({benchmark_accuracy*100 :.2f}%)')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.savefig('./learning_curve.png', dpi = 200)\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.13 ('strive')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"vscode":{"interpreter":{"hash":"57b4146e8602cb0ff91512065bdb02700ac9f9d6ea9aa046f2e5f7c3a69675f8"}}},"nbformat":4,"nbformat_minor":4}
